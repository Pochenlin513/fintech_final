{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custinfo = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/public_train_x_custinfo_full_hashed.csv')\n",
    "ccba = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/public_train_x_ccba_full_hashed.csv')\n",
    "\n",
    "cdtx = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/public_train_x_cdtx0001_full_hashed.csv')\n",
    "\n",
    "dp = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/public_train_x_dp_full_hashed.csv')\n",
    "dp.tx_amt.fillna(0, inplace=True)\n",
    "dp['amt_ntd'] = dp['tx_amt']*dp['exchg_rate']\n",
    "dp.rename(columns={'tx_date': 'date'}, inplace=True)\n",
    "dp['txbranch'] = [0 if pd.isna(x) else 1 for x in dp.txbranch.values]\n",
    "\n",
    "remit = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/public_train_x_remit1_full_hashed.csv')\n",
    "remit.rename(columns={'trans_date': 'date'}, inplace=True)\n",
    "\n",
    "alert_pub = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/public_x_alert_date.csv')\n",
    "alert_train = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/train_x_alert_date.csv')\n",
    "alert =pd.concat([alert_pub, alert_train])\n",
    "\n",
    "train_label = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/train_y_answer.csv')\n",
    "pub_label = pd.read_csv('E:/Datasets/Fintech/TrainingDataset_first/24_ESun_public_y_answer.csv')\n",
    "label = pd.concat([train_label, pub_label])\n",
    "\n",
    "# combine background infos with alert key infos\n",
    "months = ccba.byymm.unique()\n",
    "def ak_month(x):\n",
    "    \"\"\"define which month alert key belongs to\"\"\"\n",
    "    return months[months<=x][-1]\n",
    "temp = pd.merge(alert, label, on=\"alert_key\")\n",
    "alert_key_info = pd.merge(custinfo, temp, on=\"alert_key\")\n",
    "alert_key_info = alert_key_info.sort_values(by=['date'])\n",
    "alert_key_info['alert_month'] = [ak_month(x) for x in alert_key_info.date.values]\n",
    "alert_key_info.to_csv('./alert_key_info.csv', index=False)\n",
    "\n",
    "alert_key_info = pd.read_csv('./alert_key_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>date</th>\n",
       "      <th>sar_flag</th>\n",
       "      <th>alert_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171494</td>\n",
       "      <td>7a5bb395f798e329689984d41e3e4848ace9c24c52f380...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34467.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171209</td>\n",
       "      <td>95836236dac30345eaf79b450af364b869724d46adc7cd...</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1195038.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171320</td>\n",
       "      <td>98e0495b6af0455e2d2e0492a6988b3719857d505028c3...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171324</td>\n",
       "      <td>a7c9713806c471d644cd8216d4a943be6f4048e0d8a59e...</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14204286.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171357</td>\n",
       "      <td>e19835a949c31f3c41584668beeaf1159cd15a2f74c352...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25746</th>\n",
       "      <td>364624</td>\n",
       "      <td>12da1653493fda99b09d5ca125fbb1d58fa514da8d8f8b...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25747</th>\n",
       "      <td>364612</td>\n",
       "      <td>b0a578468b54394a9e61f2adb6abbe41fff7e7efb0898f...</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>262895.0</td>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25748</th>\n",
       "      <td>364610</td>\n",
       "      <td>92ce2f8b5af6ad7a6da43a416c801c2548784aeaa48aed...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29867.0</td>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25749</th>\n",
       "      <td>364666</td>\n",
       "      <td>e01690825649486bf76cfb69ff32c972eee57e072c2331...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25750</th>\n",
       "      <td>365073</td>\n",
       "      <td>7224e3a067b5e90c9b2a5bdbcfe81884505ab44f0566ae...</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83133.0</td>\n",
       "      <td>3</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25751 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alert_key                                            cust_id  \\\n",
       "0         171494  7a5bb395f798e329689984d41e3e4848ace9c24c52f380...   \n",
       "1         171209  95836236dac30345eaf79b450af364b869724d46adc7cd...   \n",
       "2         171320  98e0495b6af0455e2d2e0492a6988b3719857d505028c3...   \n",
       "3         171324  a7c9713806c471d644cd8216d4a943be6f4048e0d8a59e...   \n",
       "4         171357  e19835a949c31f3c41584668beeaf1159cd15a2f74c352...   \n",
       "...          ...                                                ...   \n",
       "25746     364624  12da1653493fda99b09d5ca125fbb1d58fa514da8d8f8b...   \n",
       "25747     364612  b0a578468b54394a9e61f2adb6abbe41fff7e7efb0898f...   \n",
       "25748     364610  92ce2f8b5af6ad7a6da43a416c801c2548784aeaa48aed...   \n",
       "25749     364666  e01690825649486bf76cfb69ff32c972eee57e072c2331...   \n",
       "25750     365073  7224e3a067b5e90c9b2a5bdbcfe81884505ab44f0566ae...   \n",
       "\n",
       "       risk_rank  occupation_code  total_asset  AGE  date  sar_flag  \\\n",
       "0              1              4.0      34467.0    4     0         0   \n",
       "1              3             12.0    1195038.0    3     0         0   \n",
       "2              1             12.0       1038.0    6     0         0   \n",
       "3              3             19.0   14204286.0    9     0         0   \n",
       "4              1             19.0        104.0    5     0         0   \n",
       "...          ...              ...          ...  ...   ...       ...   \n",
       "25746          1             19.0          0.0    5   393         0   \n",
       "25747          1             16.0     262895.0    4   393         0   \n",
       "25748          1             12.0      29867.0    4   393         0   \n",
       "25749          1              9.0          0.0    3   393         0   \n",
       "25750          3             19.0      83133.0    3   393         0   \n",
       "\n",
       "       alert_month  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "25746          365  \n",
       "25747          365  \n",
       "25748          365  \n",
       "25749          365  \n",
       "25750          365  \n",
       "\n",
       "[25751 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alert_key_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-20\n",
    "\n",
    "def dp_trans_type(x):\n",
    "    \"\"\"define trans type based on cross_bank, txbranch, ATM columns\"\"\"\n",
    "    if np.array_equal(x, [0,0,1]):\n",
    "        return 0 # withdraw\n",
    "    elif np.array_equal(x, [0,0,0]):\n",
    "        return 1 # online pay\n",
    "    elif np.array_equal(x, [0,1,1]):\n",
    "        return 2 # intra-bank trans\n",
    "    elif np.array_equal(x, [1,1,1]):\n",
    "        return 3 # inter-bank trans\n",
    "\n",
    "def dp_tx_type(x):\n",
    "    \"\"\"define if it is '臨櫃現金交易' \"\"\"\n",
    "    return np.array_equal(x, [1,12])+0\n",
    "\n",
    "def count_likely_trans(trans, thres=0.05): \n",
    "    \"\"\"return the max count of transactions with difference smaller than threshold ratio\"\"\"\n",
    "    max_cnt = 0\n",
    "    trans = (trans//100)*100\n",
    "    unq_trans, unq_cnt = np.unique(trans, return_counts=True)\n",
    "    for i in range(len(unq_trans)):\n",
    "        base = unq_trans[i]\n",
    "        r = np.abs((unq_trans / base)-1)\n",
    "        cnt = sum(unq_cnt[r<=thres])-1\n",
    "        if cnt > max_cnt:\n",
    "            max_cnt = cnt\n",
    "    return max_cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cdtx features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdtx_keys = ['cdtx_n_country', 'cdtx_n_country_switch', 'cdtx_max_country', 'cdtx_n_foreign', 'cdtx_n_foreign_switch', 'cdtx_n_cur', 'cdtx_n_cur_switch', 'cdtx_n_forcur',\\\n",
    "             'cdtx_n_forcur_switch', 'cdtx_tx_sum', 'cdtx_likely_trans_05', 'cdtx_likely_trans_10', 'cdtx_tx_num']\n",
    "def feat_cdtx(start, end, data_c):\n",
    "    data = data_c[(data_c.date > start) & (data_c.date <= end)]\n",
    "    if len(data)==0:\n",
    "        return {k: 0 for k in cdtx_keys}\n",
    "    data['binary_country'] = (data.country==130) + 0\n",
    "    data['binary_currency'] = (data.cur_type==47) + 0\n",
    "    cdtx_feat = dict()\n",
    "\n",
    "    # transaction country\n",
    "    cdtx_feat['cdtx_n_country'] = len(set(data.country))\n",
    "    cdtx_feat['cdtx_n_country_switch'] = sum(data.country.diff()!=0)\n",
    "    cdtx_feat['cdtx_max_country'] = data.country.value_counts().max()\n",
    "    cdtx_feat['cdtx_n_foreign'] = sum(data.binary_country==0)\n",
    "    cdtx_feat['cdtx_n_foreign_switch'] = sum(data.binary_country.diff()!=0)\n",
    "    # transaction currency\n",
    "    cdtx_feat['cdtx_n_cur'] = len(set(data.cur_type))\n",
    "    cdtx_feat['cdtx_n_cur_switch'] = sum(data.cur_type.diff()!=0)\n",
    "    cdtx_feat['cdtx_n_forcur'] = sum(data.binary_currency==0)\n",
    "    cdtx_feat['cdtx_n_forcur_switch'] = sum(data.binary_currency.diff()!=0)\n",
    "    # transaction amount\n",
    "    cdtx_feat['cdtx_tx_sum'] = np.log(data.amt.sum()+eps)\n",
    "    cdtx_feat['cdtx_likely_trans_05'] = count_likely_trans(data.amt.values, 0.05)\n",
    "    cdtx_feat['cdtx_likely_trans_10'] = count_likely_trans(data.amt.values, 0.10)\n",
    "    # num transaction\n",
    "    cdtx_feat['cdtx_tx_num'] = len(data)\n",
    "\n",
    "    return cdtx_feat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_keys = ['dp_trans0', 'dp_trans1', 'dp_trans2', 'dp_trans3', 'dp_tx0', 'dp_tx1', 'dp_CR_sum', 'dp_CR_likely_trans_05', 'dp_CR_likely_trans_10', 'dp_DB_sum', 'dp_DB_likely_trans_05', 'dp_DB_likely_trans_10', \\\n",
    "           'dp_tx_sum', 'dp_tx_likely_trans_05', 'dp_tx_likely_trans_10', 'dp_neg_sum', 'dp_n_CR', 'dp_n_DB', 'dp_n_tx', 'dp_n_neg']\n",
    "def feat_dp(start, end, data_c):\n",
    "    data = data_c[(data_c.date > start) & (data_c.date <= end)]\n",
    "    if len(data)==0:\n",
    "        return {k: 0 for k in dp_keys}\n",
    "    trans_types = np.array([dp_trans_type(x) for x in dp[['cross_bank', 'txbranch', 'ATM']]])\n",
    "    tx_types = np.array([dp_tx_type(x) for x in dp[['tx_type', 'info_asset_code']]])\n",
    "    dp_feat = dict()\n",
    "\n",
    "    # transaction type\n",
    "    dp_feat['dp_trans0'] = sum(trans_types==0)\n",
    "    dp_feat['dp_trans1'] = sum(trans_types==1)\n",
    "    dp_feat['dp_trans2'] = sum(trans_types==2)\n",
    "    dp_feat['dp_trans3'] = sum(trans_types==3)\n",
    "    # tx type\n",
    "    dp_feat['dp_tx0'] = sum(tx_types==0)\n",
    "    dp_feat['dp_tx1'] = sum(tx_types==1)\n",
    "\n",
    "    # transaction amount\n",
    "    data_pos = data[data.amt_ntd>=0]\n",
    "    data_neg = data[data.amt_ntd<0]\n",
    "    dp_feat['dp_CR_sum'] = np.log(data_pos[data_pos.debit_credit=='CR'].amt_ntd.sum()+eps)\n",
    "    dp_feat['dp_CR_likely_trans_05'] = count_likely_trans(data_pos[data_pos.debit_credit=='CR'].amt_ntd.values, 0.05)\n",
    "    dp_feat['dp_CR_likely_trans_10'] = count_likely_trans(data_pos[data_pos.debit_credit=='CR'].amt_ntd.values, 0.10)\n",
    "    dp_feat['dp_DB_sum'] = np.log(data_pos[data_pos.debit_credit=='DB'].amt_ntd.sum()+eps)\n",
    "    dp_feat['dp_DB_likely_trans_05'] = count_likely_trans(data_pos[data_pos.debit_credit=='DB'].amt_ntd.values, 0.05)\n",
    "    dp_feat['dp_DB_likely_trans_10'] = count_likely_trans(data_pos[data_pos.debit_credit=='DB'].amt_ntd.values, 0.10)\n",
    "    dp_feat['dp_tx_sum'] = np.log(data_pos.amt_ntd.sum()+eps)\n",
    "    dp_feat['dp_tx_likely_trans_05'] = count_likely_trans(data_pos.amt_ntd.values, 0.05)\n",
    "    dp_feat['dp_tx_likely_trans_10'] = count_likely_trans(data_pos.amt_ntd.values, 0.10)\n",
    "    dp_feat['dp_neg_sum'] = np.log(np.abs(data_neg.amt_ntd.sum())+eps)\n",
    "    # num transaction\n",
    "    dp_feat['dp_n_CR'] = len(data_pos[data_pos.debit_credit=='CR'])\n",
    "    dp_feat['dp_n_DB'] = len(data_pos[data_pos.debit_credit=='DB'])\n",
    "    dp_feat['dp_n_tx'] = len(data_pos)\n",
    "    dp_feat['dp_n_neg'] = len(data_neg)\n",
    "    return dp_feat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define remit features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remit_keys = ['remit_n_trans_type', 'remit_trans0', 'remit_trans1', 'remit_trans2', 'remit_trans3', 'remit_trans4', 'remit_tx_sum', 'remit_tx_likely_trans05', 'remit_tx_likely_trans10', 'remit_tx_num']\n",
    "def feat_remit(start, end, data_c):\n",
    "    data = data_c[(data_c.date > start) & (data_c.date <= end)]\n",
    "    if len(data)==0:\n",
    "        return {k: 0 for k in remit_keys}\n",
    "\n",
    "    remit_feat = dict()\n",
    "\n",
    "    # trans type\n",
    "    remit_feat['remit_n_trans_type'] = len(set(data.trans_no))\n",
    "    remit_feat['remit_trans0'] = len(data[data.trans_no==0])\n",
    "    remit_feat['remit_trans1'] = len(data[data.trans_no==1])\n",
    "    remit_feat['remit_trans2'] = len(data[data.trans_no==2])\n",
    "    remit_feat['remit_trans3'] = len(data[data.trans_no==3])\n",
    "    remit_feat['remit_trans4'] = len(data[data.trans_no==4])\n",
    "    # transaction amt\n",
    "    remit_feat['remit_tx_sum'] = np.log(remit.trade_amount_usd.sum()+eps)\n",
    "    remit_feat['remit_tx_likely_trans05'] = count_likely_trans(data.trade_amount_usd.values, 0.05)\n",
    "    remit_feat['remit_tx_likely_trans10'] = count_likely_trans(data.trade_amount_usd.values, 0.10)\n",
    "    # num transaction\n",
    "    remit_feat['remit_tx_num'] = len(data)\n",
    "\n",
    "\n",
    "    return remit_feat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ccba and custinfo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccba_keys = ['lupay', 'cycam', 'usgam', 'clamt', 'csamt', 'inamt', 'cucsm', 'cucah']\n",
    "def feat_ccba(ak_month, data_c):\n",
    "    data = data_c[data_c.byymm==ak_month]\n",
    "    if data.empty:\n",
    "        return np.zeros(len(ccba_keys))\n",
    "    return [np.log(x+eps) if x>=0 else -np.log(-x+eps) for x in data.loc[:,ccba_keys].values[0]]\n",
    "\n",
    "def feat_custinfo(ak, data_c):\n",
    "    return np.log(data_c[data_c.alert_key==ak].total_asset.item()+eps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7708 [00:00<?, ?it/s]c:\\Users\\PoChen\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\Users\\PoChen\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  0%|          | 1/7708 [00:03<6:27:54,  3.02s/it]c:\\Users\\PoChen\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "c:\\Users\\PoChen\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|██████████| 7708/7708 [34:00<00:00,  3.78it/s]  \n"
     ]
    }
   ],
   "source": [
    "ak_group = alert_key_info.groupby('cust_id')\n",
    "cdtx_group = cdtx.groupby('cust_id')\n",
    "dp_group = dp.groupby('cust_id')\n",
    "remit_group = remit.groupby('cust_id')\n",
    "ccba_group = ccba.groupby('cust_id')\n",
    "\n",
    "custs = custinfo.cust_id.unique()\n",
    "all_data = []\n",
    "check_shape = []\n",
    "for cust in tqdm(custs):\n",
    "\n",
    "    try: ak_info_c = ak_group.get_group(cust).reset_index()\n",
    "    except: ak_info_c=pd.DataFrame([])\n",
    "    try: cdtx_c = cdtx_group.get_group(cust)\n",
    "    except: cdtx_c=pd.DataFrame([])\n",
    "    try: dp_c = dp_group.get_group(cust)\n",
    "    except: dp_c=pd.DataFrame([])\n",
    "    try: remit_c = remit_group.get_group(cust)\n",
    "    except: remit_c=pd.DataFrame([])\n",
    "    try: ccba_c = ccba_group.get_group(cust)\n",
    "    except: ccba_c=pd.DataFrame([])\n",
    "\n",
    "    #for ak_d in ak_info_c.date.values:\n",
    "    for idx, ak_row in ak_info_c.iterrows():\n",
    "        start_date = 0 if idx==0 else ak_info_c.iloc[idx-1,:].date.item()\n",
    "        end_date = ak_row.date\n",
    "        \n",
    "        period_cdtx_feat = list(feat_cdtx(start_date, end_date, cdtx_c).values()) if not cdtx_c.empty else np.zeros(len(cdtx_keys))\n",
    "        period_dp_feat = list(feat_dp(start_date, end_date, dp_c).values()) if not dp_c.empty else np.zeros(len(dp_keys))\n",
    "        period_remit_feat = list(feat_remit(start_date, end_date, remit_c).values()) if not remit_c.empty else np.zeros(len(remit_keys))\n",
    "\n",
    "        day5_cdtx_feat = list(feat_cdtx(end_date-5, end_date, cdtx_c).values()) if not cdtx_c.empty else np.zeros(len(cdtx_keys))\n",
    "        day5_dp_feat = list(feat_dp(end_date-5, end_date, dp_c).values()) if not dp_c.empty else np.zeros(len(dp_keys))\n",
    "        day5_remit_feat = list(feat_remit(end_date-5, end_date, remit_c).values()) if not remit_c.empty else np.zeros(len(remit_keys))\n",
    "\n",
    "        day10_cdtx_feat = list(feat_cdtx(end_date-10, end_date, cdtx_c).values()) if not cdtx_c.empty else np.zeros(len(cdtx_keys))\n",
    "        day10_dp_feat = list(feat_dp(end_date-10, end_date, dp_c).values()) if not dp_c.empty else np.zeros(len(dp_keys))\n",
    "        day10_remit_feat = list(feat_remit(end_date-10, end_date, remit_c).values()) if not remit_c.empty else np.zeros(len(remit_keys))\n",
    "\n",
    "        ccba_feat = feat_ccba(ak_row.alert_month, ccba_c) if not ccba_c.empty else np.zeros(len(ccba_keys))\n",
    "        custinfo_feat = feat_custinfo(ak_row.alert_key, ak_info_c)\n",
    "\n",
    "        cust_data = np.hstack([period_cdtx_feat, period_dp_feat, period_remit_feat, day5_cdtx_feat, day5_dp_feat, day5_remit_feat, day10_cdtx_feat, day10_dp_feat, day10_remit_feat, ccba_feat, custinfo_feat, ak_row.alert_key, ak_row.sar_flag]).flatten()\n",
    "\n",
    "        check_shape.append(cust_data.shape[0])\n",
    "        assert cust_data.shape[0] == 140, \"shape error\"\n",
    "        all_data.append(cust_data)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = []\n",
    "feat_names += ['period_'+n for n in cdtx_keys]\n",
    "feat_names += ['period_'+n for n in dp_keys]\n",
    "feat_names += ['period_'+n for n in remit_keys]\n",
    "feat_names += ['day5_'+n for n in cdtx_keys]\n",
    "feat_names += ['day5_'+n for n in dp_keys]\n",
    "feat_names += ['day5_'+n for n in remit_keys]\n",
    "feat_names += ['day10_'+n for n in cdtx_keys]\n",
    "feat_names += ['day10_'+n for n in dp_keys]\n",
    "feat_names += ['day10_'+n for n in remit_keys]\n",
    "feat_names += ['ccba_'+n for n in ccba_keys]\n",
    "feat_names += ['custinfo_total_asset']\n",
    "feat_names += ['alert_key']\n",
    "feat_names += ['sar_flag']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as featuresV2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.DataFrame(all_data, columns=feat_names)\n",
    "output_data.drop_duplicates(inplace=True)\n",
    "output_data.to_csv('./featuresV2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae86156d6f7d93291eceaab1685671e020c3dd6969eb076e1ed41d8024233f22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
